# 数据预处理

使用正确的特征来构建正确的模型，以完成既定的任务。

数据预处理需要根据数据本身的特性进行，有不同的格式和不同的要求，有缺失值要填，有无效数据要剔，有冗余维要选，这些步骤都和数据本身的特性紧密相关。

数据预处理大致三个步骤：数据的准备、数据的转换、数据的输出。本章将使用scikit-learn来转换数据，以便我们将处理后的数据应用到算法中，也可以提高算法模型的准确度。本章介绍几种数据转换的方法：

- 调整数据尺度（Rescale Data）。
- 正态化数据（Standardize Data）。
- 标准化数据（Normalize Data）。
- 二值数据（Binarize Data）。

## 1.为什么需要算法处理

不同的算法对数据有不同的假定，需要按照不同的方式转换数据，当然，如果按照算法的规则来准备数据，算法就可以产生一个准确度比较高的模型。

## 2.格式化数据

本章会介绍四种不同的方法来格式化数据，这四种方法都会按照统一流程来处理数据：

- 导入数据
- 按照算法的输入和输出整理数据
- 格式化输入数据
- 总结显示数据的变化

scikit-learn提供了两种标准的格式化数据的方法，每一种方法都有适用的算法。利用这两种方法整理的数据，可以直接用来训练算法模型。在scikit-learn的说明文档中，也有这两种方法的详细说明：

- **适合和多重变换**（Fit and Multiple Transform）
- **适合和变换组合**（Combined Fit-and-Transform）

推荐优先选择适合和多重变换方法。首先使用`fit()`函数来准备数据转换的参数，然后调用`transform()`函数来做数据的预处理。适合和变换组合对绘图或汇总处理具有非常好的效果。

## 3.调整数据尺度

如果数据的各个属性按照不同的方式度量数据，那么调整数据的尺度让所有的属性按照相同的尺度来度量数据。这个方法通常会让数据的所有属性标准化，并将数据转换成0和1之间的值，这对于很多算法时很有用的。

在统计学中，按照对事物描述的精确度，对所采用的尺度从低级到高级分成几个层次：

- 定类尺度
- 定序尺度
- 定距尺度
- 定比尺度

定类尺度是对事物类别属性的一种测度，按照事物的属性进行分组或分类。

定序尺度是对事务之间的等级或次序之间间距的测量，可以比较优劣或排序。

定距尺度和定比尺度是对事物类别或次序之间间距的测量，定距尺度的特点是其不仅能将事物区分为不同的类型并进行排序，并且可以准确地指出类别之间的差距。

定比尺度则更近一步，它和定距尺度的差别在于它有一个固定的绝对“零”点。由于这两种测量尺度在绝大多数统计分析中没有本质的差别，所以很多时候都没有严格的区分。

在scikit-learn中，可以通过MinMaxScaler类来调整数据尺度。将不同计量单位的数据统一成相同的尺度，利于对事物的分类或分组。实际上，MinMaxScaler是将属性缩放到一个指定范围，或者对数据进行标准化并将数据都聚集到0附近，方差为1。数据尺度的统一，往往能提高与距离相关的算法的准确度（如K近邻算法）。下面举一个例子。

```python
from pandas import read_csv
from numpy import set_printoptions
from sklearn.preprocessing import MinMaxScaler

# 导入数据
filename = 'pima_data.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
data = read_csv(filename, names=names)
# 将数据分为输入数据和输出结果
array = data.values
X = array[:,0:8]
Y = array[:, 8]
transformer = MinMaxScaler(feature_range=(0,1))
# 数据转换
newX = transformer.fit_transform(X)
# 设定数据的打印格式
set_printoptions(precision=3)
print(newX)
```

执行结果如下，可以看到所有的数据都按照设定的分布区间进行分布。

```
[[0.353 0.744 0.59  ... 0.501 0.234 0.483]
 [0.059 0.427 0.541 ... 0.396 0.117 0.167]
 [0.471 0.92  0.525 ... 0.347 0.254 0.183]
```

## 4.正态化数据

正态化数据（Standardize Data）是有效的处理符合高斯分布的数据的手段，输出结果以0为中位数，方差为1，并作为假定数据符合高斯分布的算法的输入。这些算法有线性回归、逻辑回归和线性判别分析等。在这里可以通过scikit-learn提供的StandardScaler类进行正态化数据处理。代码如下：

```python
from pandas import read_csv
from numpy import set_printoptions
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler


    # 导入数据
    filename = 'pima_data.csv'
    names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
    data = read_csv(filename, names=names)
    # 将数据分为输入数据和输出结果
    array = data.values
    X = array[:, 0:8]
    Y = array[:, 8]
    transformer = StandardScaler()
    # 数据转换
    newX = transformer.fit_transform(X)
    # 设定数据的打印格式
    set_printoptions(precision=3)
    print(newX)
```

```
[[ 0.64   0.848  0.15  ...  0.204  0.468  1.426]
 [-0.845 -1.123 -0.161 ... -0.684 -0.365 -0.191]
 [ 1.234  1.944 -0.264 ... -1.103  0.604 -0.106]
 ...
 [ 0.343  0.003  0.15  ... -0.735 -0.685 -0.276]
 [-0.845  0.16  -0.471 ... -0.24  -0.371  1.171]
 [-0.845 -0.873  0.046 ... -0.202 -0.474 -0.871]]

```

## 5.标准化数据

标准化数据（Normalize Data）处理是将每一行的数据的距离处理成1（在线性代数中矢量距离为1）的数据又叫作“归一化”处理，适合处理稀疏数据（具有很多0的数据），归一化处理的数据对使用权重输入的神经网络和使用距离的K近邻算法的准确度的提升有显著作用。使用scikit-learn中的Normalizer类实现。代码如下：

```python
from pandas import read_csv
from numpy import set_printoptions
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer


# 导入数据
    filename = 'pima_data.csv'
    names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
    data = read_csv(filename, names=names)
    # 将数据分为输入数据和输出结果
    array = data.values
    X = array[:, 0:8]
    Y = array[:, 8]
    transformer = Normalizer()
    # 数据转换
    newX = transformer.fit_transform(X)
    # 设定数据的打印格式
    set_printoptions(precision=3)
    print(newX)
```

```
[[0.034 0.828 0.403 ... 0.188 0.004 0.28 ]
 [0.008 0.716 0.556 ... 0.224 0.003 0.261]
 [0.04  0.924 0.323 ... 0.118 0.003 0.162]
 ...
 [0.027 0.651 0.388 ... 0.141 0.001 0.161]
 [0.007 0.838 0.399 ... 0.2   0.002 0.313]
 [0.008 0.736 0.554 ... 0.241 0.002 0.182]]
```

这里每一行的元素平方和是1。

## 6.二值数据

二值数据（Binarize Data）是使用值将数据转化为二值，大于阈值设置为1，小于阈值设置为0。这个过程被叫做**二分数据**或**阈值转换**。在生成明确值或特征工程增加属性的适合使用，使用scikit-learn中的Binarizer类实现。代码如下：

```python
from pandas import read_csv
from numpy import set_printoptions
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
from sklearn.preprocessing import Binarizer


# 导入数据
    filename = 'pima_data.csv'
    names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
    data = read_csv(filename, names=names)
    # 将数据分为输入数据和输出结果
    array = data.values
    X = array[:, 0:8]
    Y = array[:, 8]
    transformer = Binarizer(threshold=0.0)
    # 数据转换
    newX = transformer.fit_transform(X)
    # 设定数据的打印格式
    set_printoptions(precision=3)
    print(newX)
```

```
[[1. 1. 1. ... 1. 1. 1.]
 [1. 1. 1. ... 1. 1. 1.]
 [1. 1. 1. ... 1. 1. 1.]
 ...
 [1. 1. 1. ... 1. 1. 1.]
 [1. 1. 1. ... 1. 1. 1.]
 [1. 1. 1. ... 1. 1. 1.]]
```

## 7.总结

这四种方法适用于不同的场景，可以在实践中根据不同的算法模型来选择不同的预处理方法。下一章将会学习如何选择的特征属性来预测（分类与回归）模型。

